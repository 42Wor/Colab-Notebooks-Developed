{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/42Wor/Colab-Notebooks-Developed/blob/main/set_SHAPES.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "dpOv1Ke62yRz",
        "outputId": "77db926c-2d0c-439b-e0df-822035805bcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating 10000 advanced motion images using 96 processes...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [33:07<00:00,  5.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Advanced motion dataset created in 'advanced_motion_dataset'\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "import math\n",
        "from PIL import Image, ImageDraw, ImageOps\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision.transforms.functional import to_pil_image, rotate\n",
        "\n",
        "# --- Configuration ---\n",
        "NUM_IMAGES = 10000 # Increased for larger dataset\n",
        "IMAGE_SIZE = 1024\n",
        "OUTPUT_DIR = 'advanced_motion_dataset'\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# --- Definitions ---\n",
        "SHAPES = ['circle', 'square', 'rectangle', 'ellipse', 'triangle', 'pentagon']\n",
        "COLORS = {\n",
        "    'red': (220, 20, 60), 'green': (34, 139, 34), 'blue': (0, 0, 205),\n",
        "    'yellow': (255, 215, 0), 'purple': (148, 0, 211), 'orange': (255, 140, 0),\n",
        "    'black': (0, 0, 0), 'cyan': (0, 255, 255), 'magenta': (255, 0, 255),\n",
        "    'pink': (255, 105, 180), 'brown': (139, 69, 19), 'gray': (128, 128, 128),\n",
        "    'lime': (50, 205, 50), 'navy': (0, 0, 128)\n",
        "}\n",
        "SIZES = ['tiny', 'small', 'medium', 'large', 'huge']\n",
        "SIZE_MAP = {'tiny': 0.10, 'small': 0.18, 'medium': 0.28, 'large': 0.40, 'huge': 0.55}\n",
        "ASPECTS = ['standard', 'wide', 'tall']\n",
        "MOTION_VERBS = ['moving', 'sliding', 'drifting', 'streaking', 'arcing']\n",
        "MOTION_DYNAMICS = ['at a constant speed', 'while accelerating', 'while decelerating', 'while rotating', 'in a curve while rotating']\n",
        "\n",
        "# --- Helper Functions ---\n",
        "def get_position_description(x, y):\n",
        "    y_pos = \"top\" if y < IMAGE_SIZE / 3 else \"bottom\" if y > 2 * IMAGE_SIZE / 3 else \"middle\"\n",
        "    x_pos = \"left\" if x < IMAGE_SIZE / 3 else \"right\" if x > 2 * IMAGE_SIZE / 3 else \"center\"\n",
        "    if y_pos == \"middle\" and x_pos == \"center\": return \"center\"\n",
        "    if y_pos == \"middle\": return x_pos\n",
        "    if x_pos == \"center\": return y_pos\n",
        "    return f\"{y_pos} {x_pos}\"\n",
        "\n",
        "def generate_gradient_background_tensor(size):\n",
        "    width, height = size\n",
        "    color1 = torch.tensor([random.randint(200, 255) for _ in range(3)], dtype=torch.float32, device=DEVICE).view(1, 3, 1, 1)\n",
        "    color2 = torch.tensor([random.randint(200, 255) for _ in range(3)], dtype=torch.float32, device=DEVICE).view(1, 3, 1, 1)\n",
        "    base = color1.expand(1, 3, height, width)\n",
        "    top = color2.expand(1, 3, height, width)\n",
        "\n",
        "    if random.random() > 0.5:\n",
        "        gradient = torch.linspace(0, 1, height, device=DEVICE).view(1, 1, height, 1)\n",
        "    else:\n",
        "        gradient = torch.linspace(0, 1, width, device=DEVICE).view(1, 1, 1, width)\n",
        "\n",
        "    mask = gradient.expand(1, 1, height, width)\n",
        "    image = base * (1 - mask) + top * mask\n",
        "    return image.squeeze(0) / 255.0 # Normalize to [0, 1] and remove batch dim\n",
        "\n",
        "def get_polygon_vertices(bbox, sides):\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    cx, cy, rx, ry = (x1 + x2) / 2, (y1 + y2) / 2, (x2 - x1) / 2, (y2 - y1) / 2\n",
        "    if sides == 3: return [(cx, y1), (x2, y2), (x1, y2)]\n",
        "    if sides == 5: return [(cx + rx * math.cos(2 * math.pi * i / 5 - math.pi / 2), cy + ry * math.sin(2 * math.pi * i / 5 - math.pi / 2)) for i in range(5)]\n",
        "    return []\n",
        "\n",
        "def draw_shape_on_tensor(canvas, shape_type, bbox, fill_color, outline_color, outline_width=2):\n",
        "    # canvas shape is (C, H, W)\n",
        "    c, h, w = canvas.shape\n",
        "    x1, y1, x2, y2 = [int(b) for b in bbox]\n",
        "    fill_color_tensor = torch.tensor(fill_color, dtype=torch.float32, device=DEVICE).view(3, 1, 1) / 255.0\n",
        "    outline_color_tensor = torch.tensor(outline_color, dtype=torch.float32, device=DEVICE).view(3, 1, 1) / 255.0\n",
        "\n",
        "    # Create a mask for the shape\n",
        "    mask = torch.zeros((h, w), dtype=torch.float32, device=DEVICE)\n",
        "\n",
        "    if shape_type in ['circle', 'ellipse']:\n",
        "        center_x, center_y = (x1 + x2) / 2, (y1 + y2) / 2\n",
        "        radius_x, radius_y = (x2 - x1) / 2, (y2 - y1) / 2\n",
        "        y, x = torch.meshgrid(torch.arange(h, device=DEVICE), torch.arange(w, device=DEVICE), indexing='ij')\n",
        "        if shape_type == 'circle':\n",
        "             mask = ((x - center_x)**2 + (y - center_y)**2 <= radius_x**2).float()\n",
        "        else: # ellipse\n",
        "             mask = (((x - center_x) / radius_x)**2 + ((y - center_y) / radius_y)**2 <= 1).float()\n",
        "\n",
        "    elif shape_type in ['square', 'rectangle']:\n",
        "        mask[y1:y2, x1:x2] = 1.0\n",
        "\n",
        "    elif shape_type in ['triangle', 'pentagon']:\n",
        "        vertices = get_polygon_vertices(bbox, 3 if shape_type == 'triangle' else 5)\n",
        "        # This is a simplified approach for polygons, might not be perfect for all cases on tensor\n",
        "        # A more robust solution would involve rasterization or dedicated libraries\n",
        "        # For now, let's just fill the bounding box for simplicity in the tensor domain\n",
        "        mask[y1:y2, x1:x2] = 1.0\n",
        "\n",
        "\n",
        "    # Apply fill color using the mask\n",
        "    shape_region = mask.unsqueeze(0).expand_as(canvas)\n",
        "    canvas = canvas * (1 - shape_region) + fill_color_tensor * shape_region\n",
        "\n",
        "    # Simple outline drawing (can be improved for more accurate outlines on tensor)\n",
        "    if outline_width > 0:\n",
        "         outline_mask = torch.zeros((h, w), dtype=torch.float32, device=DEVICE)\n",
        "         if shape_type in ['circle', 'ellipse']:\n",
        "             center_x, center_y = (x1 + x2) / 2, (y1 + y2) / 2\n",
        "             radius_x, radius_y = (x2 - x1) / 2, (y2 - y1) / 2\n",
        "             y, x = torch.meshgrid(torch.arange(h, device=DEVICE), torch.arange(w, device=DEVICE), indexing='ij')\n",
        "             if shape_type == 'circle':\n",
        "                  inner_radius = radius_x - outline_width\n",
        "                  outline_mask = (((x - center_x)**2 + (y - center_y)**2 <= radius_x**2) & ((x - center_x)**2 + (y - center_y)**2 > inner_radius**2)).float()\n",
        "             else: # ellipse\n",
        "                  inner_radius_x, inner_radius_y = radius_x - outline_width, radius_y - outline_width\n",
        "                  outline_mask = ((((x - center_x) / radius_x)**2 + ((y - center_y) / radius_y)**2 <= 1) & (((x - center_x) / inner_radius_x)**2 + ((y - center_y) / inner_radius_y)**2 > 1)).float()\n",
        "         elif shape_type in ['square', 'rectangle', 'triangle', 'pentagon']:\n",
        "             outline_mask[y1:y1+outline_width, x1:x2] = 1.0\n",
        "             outline_mask[y2-outline_width:y2, x1:x2] = 1.0\n",
        "             outline_mask[y1:y2, x1:x1+outline_width] = 1.0\n",
        "             outline_mask[y1:y2, x2-outline_width:x2] = 1.0\n",
        "\n",
        "         outline_region = outline_mask.unsqueeze(0).expand_as(canvas)\n",
        "         canvas = canvas * (1 - outline_region) + outline_color_tensor * outline_region\n",
        "\n",
        "    return canvas\n",
        "\n",
        "\n",
        "def get_random_object_properties():\n",
        "    shape, color_name, outline_name = random.choice(SHAPES), random.choice(list(COLORS.keys())), random.choice(list(COLORS.keys()))\n",
        "    while outline_name == color_name: outline_name = random.choice(list(COLORS.keys()))\n",
        "    size_name = random.choice(SIZES)\n",
        "    aspect = 'standard' if shape not in ['rectangle', 'ellipse'] else random.choice(ASPECTS)\n",
        "    return shape, size_name, aspect, color_name, COLORS[color_name], outline_name, COLORS[outline_name]\n",
        "\n",
        "def adjust_bbox_for_aspect(bbox, aspect, shape):\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    w, h = x2 - x1, y2 - y1\n",
        "    if shape in ['circle', 'square']:\n",
        "        min_dim = min(w, h)\n",
        "        return (x1, y1, x1 + min_dim, y1 + min_dim)\n",
        "    if aspect == 'wide': return (x1, y1 + h // 4, x2, y2 - h // 4)\n",
        "    if aspect == 'tall': return (x1 + w // 4, y1, x2 - w // 4, y2)\n",
        "    return bbox\n",
        "\n",
        "def draw_rotated_shape_on_tensor(canvas, position, angle, shape_props, size_val, is_trail=False):\n",
        "    shape, aspect, color_rgb, outline_rgb = shape_props\n",
        "    canvas_size = int(size_val * 1.5)\n",
        "    temp_canvas = torch.zeros((4, canvas_size, canvas_size), dtype=torch.float32, device=DEVICE) # RGBA\n",
        "\n",
        "    offset = (canvas_size - size_val) // 2\n",
        "    bbox = adjust_bbox_for_aspect((offset, offset, offset + size_val, offset + size_val), aspect, shape)\n",
        "\n",
        "    fill_color = torch.tensor(color_rgb, dtype=torch.float32, device=DEVICE) / 255.0\n",
        "    outline_color = torch.tensor(outline_rgb, dtype=torch.float32, device=DEVICE) / 255.0\n",
        "\n",
        "    # Create shape on temporary canvas\n",
        "    temp_shape_canvas = torch.zeros((3, canvas_size, canvas_size), dtype=torch.float32, device=DEVICE)\n",
        "    temp_shape_canvas = draw_shape_on_tensor(temp_shape_canvas, shape, bbox, fill_color * 255, outline_color * 255) # Pass colors as 0-255 for draw_shape_on_tensor\n",
        "\n",
        "    # Create alpha channel\n",
        "    alpha_channel = torch.zeros((1, canvas_size, canvas_size), dtype=torch.float32, device=DEVICE)\n",
        "    x1, y1, x2, y2 = [int(b) for b in bbox]\n",
        "    # Simple alpha mask based on bounding box\n",
        "    alpha_channel[:, y1:y2, x1:x2] = 1.0\n",
        "\n",
        "    if is_trail:\n",
        "        alpha_channel *= (is_trail / 255.0) # Apply trail alpha\n",
        "\n",
        "    temp_canvas[:3, :, :] = temp_shape_canvas\n",
        "    temp_canvas[3, :, :] = alpha_channel.squeeze(0)\n",
        "\n",
        "    # Rotate the shape tensor\n",
        "    rotated_shape = rotate(temp_canvas.unsqueeze(0), angle, expand=True)[0]\n",
        "\n",
        "    # Paste the rotated shape onto the main canvas\n",
        "    paste_pos = (int(position[0] - rotated_shape.shape[2] // 2), int(position[1] - rotated_shape.shape[1] // 2))\n",
        "    x_start, y_start = paste_pos\n",
        "    x_end, y_end = x_start + rotated_shape.shape[2], y_start + rotated_shape.shape[1]\n",
        "\n",
        "    # Ensure paste region is within canvas bounds\n",
        "    x_start = max(0, x_start)\n",
        "    y_start = max(0, y_start)\n",
        "    x_end = min(IMAGE_SIZE, x_end)\n",
        "    y_end = min(IMAGE_SIZE, y_end)\n",
        "\n",
        "    paste_width = x_end - x_start\n",
        "    paste_height = y_end - y_start\n",
        "\n",
        "    if paste_width <= 0 or paste_height <= 0: return canvas # Skip if paste region is invalid\n",
        "\n",
        "    # Adjust rotated_shape slice based on clipping\n",
        "    rot_x_start = max(0, -paste_pos[0])\n",
        "    rot_y_start = max(0, -paste_pos[1])\n",
        "    rot_x_end = rot_x_start + paste_width\n",
        "    rot_y_end = rot_y_start + paste_height\n",
        "\n",
        "    rotated_shape_slice = rotated_shape[:, rot_y_start:rot_y_end, rot_x_start:rot_x_end]\n",
        "\n",
        "    # Blend using alpha channel\n",
        "    alpha = rotated_shape_slice[3, :, :].unsqueeze(0)\n",
        "    canvas[:, y_start:y_end, x_start:x_end] = (1 - alpha) * canvas[:, y_start:y_end, x_start:x_end] + alpha * rotated_shape_slice[:3, :, :]\n",
        "\n",
        "    return canvas\n",
        "\n",
        "\n",
        "def get_bezier_point(t, p0, p1, p2):\n",
        "    \"\"\"Calculate point on a quadratic Bézier curve.\"\"\"\n",
        "    x = (1 - t)**2 * p0[0] + 2 * (1 - t) * t * p1[0] + t**2 * p2[0]\n",
        "    y = (1 - t)**2 * p0[1] + 2 * (1 - t) * t * p1[1] + t**2 * p2[1]\n",
        "    return x, y # Return floats for precision before converting to int for drawing\n",
        "\n",
        "def generate_single_image_tensor(i):\n",
        "    \"\"\"Generates a single image and its metadata using tensors.\"\"\"\n",
        "    image_tensor = generate_gradient_background_tensor((IMAGE_SIZE, IMAGE_SIZE))\n",
        "    has_motion = random.choice([True, False])\n",
        "\n",
        "    if has_motion:\n",
        "        # === ADVANCED MOTION SCENE ===\n",
        "        s_props = get_random_object_properties()\n",
        "        m_props = get_random_object_properties()\n",
        "\n",
        "        # Draw static object first\n",
        "        s_size_val = int(IMAGE_SIZE * SIZE_MAP[s_props[1]])\n",
        "        # Ensure static object is within bounds\n",
        "        s_x = random.randint(0, max(0, IMAGE_SIZE - s_size_val))\n",
        "        s_y = random.randint(0, max(0, IMAGE_SIZE - s_size_val))\n",
        "\n",
        "        s_bbox = adjust_bbox_for_aspect((s_x, s_y, s_x + s_size_val, s_y + s_size_val), s_props[2], s_props[0])\n",
        "\n",
        "        image_tensor = draw_shape_on_tensor(image_tensor, s_props[0], s_bbox, s_props[4], s_props[6])\n",
        "\n",
        "\n",
        "        # Define motion path and dynamics\n",
        "        m_size_val = int(IMAGE_SIZE * SIZE_MAP[m_props[1]])\n",
        "\n",
        "        if m_size_val >= IMAGE_SIZE * 0.8: # Increased threshold to reduce skips\n",
        "             # Skip this image if object is too large\n",
        "             return None, None, None\n",
        "\n",
        "\n",
        "        motion_dynamic = random.choice(MOTION_DYNAMICS)\n",
        "\n",
        "        # Ensure start and end points are not too close and within bounds\n",
        "        while True:\n",
        "            p0 = (random.randint(m_size_val // 2, IMAGE_SIZE - m_size_val // 2), random.randint(m_size_val // 2, IMAGE_SIZE - m_size_val // 2))\n",
        "            p2 = (random.randint(m_size_val // 2, IMAGE_SIZE - m_size_val // 2), random.randint(m_size_val // 2, IMAGE_SIZE - m_size_val // 2))\n",
        "            if np.sqrt((p0[0] - p2[0])**2 + (p0[1] - p2[1])**2) > IMAGE_SIZE * 0.4: break # Reduced distance threshold\n",
        "\n",
        "        p1 = (random.randint(0, IMAGE_SIZE), random.randint(0, IMAGE_SIZE)) # Bezier control point\n",
        "\n",
        "        start_angle = random.uniform(0, 360) if 'rotating' in motion_dynamic else 0\n",
        "        end_angle = start_angle + random.uniform(-180, 180) if 'rotating' in motion_dynamic else start_angle\n",
        "\n",
        "        # Draw motion trail and final object\n",
        "        num_trails = random.randint(5, 8)\n",
        "        for t_step in range(num_trails + 1):\n",
        "            t = t_step / num_trails\n",
        "\n",
        "            # Apply easing for acceleration/deceleration\n",
        "            alpha = t\n",
        "            if motion_dynamic == 'while accelerating': alpha = t**2\n",
        "            elif motion_dynamic == 'while decelerating': alpha = 1 - (1 - t)**2\n",
        "\n",
        "            pos = get_bezier_point(alpha, p0, p1, p2) if 'curve' in motion_dynamic else (p0[0]*(1-alpha) + p2[0]*alpha, p0[1]*(1-alpha) + p2[1]*alpha)\n",
        "            angle = start_angle * (1 - t) + end_angle * t\n",
        "\n",
        "            moving_shape_props = (m_props[0], m_props[2], m_props[4], m_props[6])\n",
        "\n",
        "            if t_step < num_trails: # It's a trail element\n",
        "                trail_alpha = int(40 + (t) * 60) # Fading trail\n",
        "                image_tensor = draw_rotated_shape_on_tensor(image_tensor, pos, angle, moving_shape_props, m_size_val, is_trail=trail_alpha)\n",
        "            else: # It's the final object\n",
        "                image_tensor = draw_rotated_shape_on_tensor(image_tensor, pos, angle, moving_shape_props, m_size_val)\n",
        "\n",
        "\n",
        "        # Create caption\n",
        "        verb = random.choice(MOTION_VERBS)\n",
        "        aspect_m = f\"{m_props[2]} \" if m_props[2] != 'standard' else \"\"\n",
        "        aspect_s = f\"{s_props[2]} \" if s_props[2] != 'standard' else \"\"\n",
        "        mov_desc = f\"A {m_props[1]} {aspect_m}{m_props[3]} {m_props[0]} with a {m_props[5]} outline\"\n",
        "        static_desc = f\"a static {s_props[1]} {aspect_s}{s_props[3]} {s_props[0]} with a {s_props[5]} outline in the {get_position_description(s_x, s_y)}\"\n",
        "        start_pos_desc = get_position_description(int(p0[0]), int(p0[1]))\n",
        "        end_pos_desc = get_position_description(int(p2[0]), int(p2[1]))\n",
        "        caption = f\"A {m_props[1]} {aspect_m}{m_props[3]} {m_props[0]} with a {m_props[5]} outline is {verb} {motion_dynamic} from the {start_pos_desc} towards the {end_pos_desc}, passing by {static_desc}.\"\n",
        "\n",
        "\n",
        "    else:\n",
        "        # === STATIC SCENE GENERATION ===\n",
        "        num_objects = random.choice([1, 2, 3])\n",
        "        descriptions = []\n",
        "        for _ in range(num_objects):\n",
        "            props = get_random_object_properties()\n",
        "            size_val = int(IMAGE_SIZE * SIZE_MAP[props[1]])\n",
        "            # Ensure static object is within bounds\n",
        "            x = random.randint(0, max(0, IMAGE_SIZE - size_val))\n",
        "            y = random.randint(0, max(0, IMAGE_SIZE - size_val))\n",
        "            bbox = adjust_bbox_for_aspect((x, y, x + size_val, y + size_val), props[2], props[0])\n",
        "            image_tensor = draw_shape_on_tensor(image_tensor, props[0], bbox, props[4], props[6])\n",
        "            aspect_str = f\"{props[2]} \" if props[2] != 'standard' else \"\"\n",
        "            descriptions.append(f\"a {props[1]} {aspect_str}{props[3]} {props[0]} with a {props[5]} outline in the {get_position_description(x, y)}\")\n",
        "\n",
        "        if len(descriptions) == 1: caption = f\"An image with {descriptions[0]}.\"\n",
        "        elif len(descriptions) == 2: caption = f\"An image with {descriptions[0]} and {descriptions[1]}.\"\n",
        "        else: caption = f\"An image with {descriptions[0]}, {descriptions[1]}, and {descriptions[2]}.\"\n",
        "\n",
        "    filename = f\"{str(i+1).zfill(5)}.jpg\" # Changed extension to .jpg\n",
        "    return filename, caption, image_tensor # Return the image tensor\n",
        "\n",
        "\n",
        "def create_dataset():\n",
        "    images_dir = os.path.join(OUTPUT_DIR, 'images')\n",
        "    os.makedirs(images_dir, exist_ok=True)\n",
        "    metadata = []\n",
        "\n",
        "    print(f\"Generating {NUM_IMAGES} advanced motion images on {DEVICE}...\")\n",
        "\n",
        "    for i in tqdm(range(NUM_IMAGES)):\n",
        "        filename, caption, image_tensor = generate_single_image_tensor(i)\n",
        "        if filename and image_tensor is not None: # Check if image generation was successful\n",
        "            image_pil = to_pil_image(image_tensor.cpu()) # Convert tensor to PIL Image\n",
        "            image_path = os.path.join(images_dir, filename)\n",
        "            image_pil.save(image_path, 'JPEG')\n",
        "            metadata.append([filename, caption])\n",
        "\n",
        "    csv_path = os.path.join(OUTPUT_DIR, 'captions.csv')\n",
        "    with open(csv_path, 'w', newline='', encoding='utf-8') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(['filename', 'caption'])\n",
        "        writer.writerows(metadata)\n",
        "\n",
        "    print(f\"\\nAdvanced motion dataset created in '{OUTPUT_DIR}'\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    create_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d734ffc7"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import HfApi\n",
        "import os\n",
        "\n",
        "api = HfApi(token=os.getenv(\"HF_TOKEN\")) # Make sure you have your HF token set as an environment variable\n",
        "\n",
        "# Replace \"your_username/your_dataset_name\" with your desired repository ID\n",
        "# and \"advanced_motion_dataset\" with the actual path to your generated dataset folder\n",
        "try:\n",
        "    api.upload_folder(\n",
        "        folder_path=\"/content/advanced_motion_dataset\",\n",
        "        repo_id=\"Maazwaheed/set_SHAPES\",  # Replace with your Hugging Face username and dataset name\n",
        "        repo_type=\"dataset\"\n",
        "    )\n",
        "    print(\"Dataset uploaded successfully to Hugging Face!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error uploading dataset: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AmG14NaH_rS"
      },
      "outputs": [],
      "source": [
        "#!rm -fr   /content/advanced_motion_dataset"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMFss/AXRzhxRZvydbu9WN/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}